{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Este proyecto es realizado por Claudia del grupo 14."
      ],
      "metadata": {
        "id": "2c9CvqX2CfzA"
      },
      "id": "2c9CvqX2CfzA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Choose a PDF file and replicate the tutorial with 5 main questions.\n",
        "**texto en negrita**"
      ],
      "metadata": {
        "id": "_oI4uupnyuDl"
      },
      "id": "_oI4uupnyuDl"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain openai pypdf python-dotenv chromadb  tiktoken -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuDOAliMzDjh",
        "outputId": "b023175f-40db-4b35-f0b2-d5123f981f3d"
      },
      "id": "zuDOAliMzDjh",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openai\n",
        "import getpass, openai, os #Instalamos la biblioteca open AI\n",
        "api_key = \"AIzaSyBYudclyrbOoorI1r8zepAb1vS-Z6Pqpng\"\n",
        "openai.apikey = api_key #autenticamos en OpenAI con mi clave API\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "TFr8VrdczNKf"
      },
      "id": "TFr8VrdczNKf",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jq #Procesar datos JSON"
      ],
      "metadata": {
        "id": "A4fvowHpzlVz",
        "outputId": "8b873eae-fb1a-40df-8d7d-a0d6812b5345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "A4fvowHpzlVz",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jq\n",
            "  Downloading jq-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (656 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jq\n",
            "Successfully installed jq-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usamos la biblioteca lanchain para importar módulos y clases para poder procesar el texto.\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "\n",
        "from langchain.text_splitter import (\n",
        "    Language,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings #utilizo un modelo de embeddings para incrustar texto en vctores\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "\n",
        "import getpass, openai, os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma #Importo la clase Chroma desde el módulo vectorstores de langchain. Sirve para trabajar con vectores de paalabras\n",
        "                                                                  #Chroma sirce para representar palabras como vectores en un espacio de alta dimensionalidad. E\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA as RQa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxtg72KVzsea",
        "outputId": "dd296a5c-bb4b-4c19-d9ac-6ea3c35f33fc"
      },
      "id": "kxtg72KVzsea",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass, openai, os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA as RQa"
      ],
      "metadata": {
        "id": "-7iFwveVu2Ae"
      },
      "id": "-7iFwveVu2Ae",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "api_key = \"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\"\n",
        "openai.apikey = api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "\n",
        "\n",
        "url_pdf = input(\"Insert the pdfurl: \")\n",
        "\n",
        "loader = PyPDFLoader(url_pdf)\n",
        "pages = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "splits = text_splitter.split_documents(pages)\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# persist_directory = './thesis_chroma/'\n",
        "\n",
        "# !rm -rf ./thesis_chroma  # remove old database files if any (linux, Mac)\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    # persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "\n",
        "llm_model = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name = llm_model, temperature = 0)\n",
        "\n",
        "#https://repositorio.uca.edu.ar/bitstream/123456789/8636/1/official-multidimensional-poverty-measures.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju-b5D280KNO",
        "outputId": "ab65a1e3-3ceb-49d1-9650-e41c234ff6e6"
      },
      "id": "ju-b5D280KNO",
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insert the pdfurl: https://repositorio.uca.edu.ar/bitstream/123456789/8636/1/official-multidimensional-poverty-measures.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA as RQa\n",
        "\n"
      ],
      "metadata": {
        "id": "2docvNaMzC00"
      },
      "id": "2docvNaMzC00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    question1 = input(\"Ask: \")\n",
        "    if question1 == \"\":\n",
        "        break\n",
        "    stuff = RQa.from_chain_type(\n",
        "        llm, retriever = vectordb.as_retriever(),\n",
        "        chain_type = \"stuff\" # default\n",
        "    )\n",
        "    stuff_result = stuff({\"query\": question1})\n",
        "    result = stuff_result['result']\n",
        "    format_response = f\"\"\"\n",
        "    Question:\n",
        "      {question1}\n",
        "    Result:\n",
        "      {result}\n",
        "    ------------ x -------------\n",
        "    \"\"\"\n",
        "    print(format_response)"
      ],
      "metadata": {
        "id": "TUnBl5JYzsMO",
        "outputId": "5da28a11-6fe7-4037-f6bf-89d66d996518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "id": "TUnBl5JYzsMO",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e8e4b840628f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquestion1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ask: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquestion1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     stuff = RQa.from_chain_type(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resultados"
      ],
      "metadata": {
        "id": "gCv-kA8eAP-8"
      },
      "id": "gCv-kA8eAP-8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "    Question:\n",
        "      ¿De qué forma las estrategias para de pobreza multidimencional reflejan mejor las condiciones reales de los países de Latinoamérica?\n",
        "    Result:\n",
        "      Las estrategias para medir la pobreza multidimensional en países de Latinoamérica han avanzado hacia una mejor comprensión de lo que las personas en situación de pobreza consideran una vida empobrecida. Aunque han enfrentado limitaciones en la implementación de estrategias puramente participativas, se han propuesto medidas que reflejan de manera más precisa las prioridades y condiciones reales de las personas en desventaja.\n",
        "    ------------ x -------------"
      ],
      "metadata": {
        "id": "fL9bbFQULR6_"
      },
      "id": "fL9bbFQULR6_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask: ¿What are the main results of the text?\n",
        "\n",
        "    Question:\n",
        "      What are the main results of the text?\n",
        "    Result:\n",
        "      The main results of the text seem to focus on the challenges and limitations faced by lower-middle-income countries in conducting large-scale participatory exercises regularly. It discusses the use of qualitative research with small samples, the potential under-representation of disadvantaged voices, and the complexities of analyzing wellbeing from multiple perspectives. The text also mentions the progress made in measuring poverty in a way that better reflects what disadvantaged individuals consider a life in poverty.\n",
        "    ------------ x -------------\n",
        "    \n",
        "Ask: What are the different ways of officialy measuring multidimensional poverty in the Latin American countries discussed in the text?\n",
        "\n",
        "    Question:\n",
        "      What are the different ways of officialy measuring multidimensional poverty in the Latin American countries discussed in the text?\n",
        "    Result:\n",
        "      The official multidimensional poverty measures in Latin American countries discussed in the text are measured using the Alkire-Foster method. This method involves selecting dimensions such as education, housing conditions, employment, health, basic services, food security, and habitat quality. These dimensions are operationalized using indicators estimated from data sources like the Living Standards Measurement Survey (LSMS). The poverty threshold is set at 1/3 of the weighted deprivation, with equal weight given to each dimension.\n",
        "    ------------ x -------------\n",
        "    \n",
        "Ask: What's the main hypothesis of the text?\n",
        "\n",
        "    Question:\n",
        "      What's the main hypothesis of the text?\n",
        "    Result:\n",
        "      The main hypothesis of the text seems to be that the process of designing and implementing official multidimensional national poverty measures, inspired by the Sustainable Development Goals (SDG) agenda, has been successful in partially reflecting some of the elements that disadvantaged people prioritize.\n",
        "    ------------ x -------------\n",
        "    \n",
        "Ask: How does the author propose one could the official multidimensional poverty systems enhance their opennes to public?\n",
        "\n",
        "    Question:\n",
        "      How does the author propose one could the official multidimensional poverty systems enhance their opennes to public?\n",
        "    Result:\n",
        "      The author suggests three areas in which official multidimensional poverty systems could enhance their openness to public reasoning. These areas include enriching the data sources used to estimate multidimensional poverty, developing complementary measures from a territorial perspective, and exploring synergies with the private sector. Additionally, the author mentions that dimensions could be chosen based on participatory deliberative processes, weights could be assigned based on how people rank these dimensions, and a poverty threshold could be set based on societal views of deprivation. However, the author also acknowledges that these approaches are not without limitations and criticisms.\n",
        "    ------------ x -------------"
      ],
      "metadata": {
        "id": "OPwM-JJX_qiR"
      },
      "id": "OPwM-JJX_qiR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Read the PDF file and write the right question and check it with GPT results"
      ],
      "metadata": {
        "id": "lc7GGq21y1YL"
      },
      "id": "lc7GGq21y1YL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Respuestas con Chat GPT 4 vs el prompt GPT\n",
        "Basado en el documento proporcionado, aquí están las respuestas a las preguntas formuladas:\n",
        "\n",
        "1. **¿De qué forma las estrategias para de pobreza multidimensional reflejan mejor las condiciones reales de los países de Latinoamérica?**\n",
        "   - Las estrategias de pobreza multidimensional en países de Latinoamérica como Colombia, Chile, El Salvador y México se han enfocado en reflejar las prioridades de las personas en situación de pobreza mediante la inclusión de dimensiones que abarcan aspectos esenciales de la vida más allá del ingreso monetario. Estos países han avanzado hacia mediciones de pobreza que mejor reflejan lo que las personas desfavorecidas consideran una vida empobrecida, aunque enfrentan limitaciones para implementar estrategias completamente participativas【17†source】.\n",
        "   **vs prompt GPT**  Las estrategias para medir la pobreza multidimensional en países de Latinoamérica han avanzado hacia una mejor comprensión de lo que las personas en situación de pobreza consideran una vida empobrecida. Aunque han enfrentado limitaciones en la implementación de estrategias puramente participativas, se han propuesto medidas que reflejan de manera más precisa las prioridades y condiciones reales de las personas en desventaja.\n",
        "   -- Podemos ver que la respuesta generada por el GPT 4 está más detallada.  La respuesta del CHAT GPT4 enfatiza las limitaciones enfrentadas en la implementación de estrategias completamente participativas de los países utilizados como modelo en el texto. Mientras tanto, la formulación proporcionada por el prompt  generaliza que se han dado metodologías para comprender la pobreza sin detallar los esfuerzos o limitaciones específicas de los países mencionados.\n",
        "\n",
        "\n",
        "2. **¿Cuáles son los principales resultados del texto?**\n",
        "   - The main findings indicate that, although the design processes of multidimensional poverty measures in Latin America have limitations, these countries have made progress towards measurements that better reflect the living conditions of disadvantaged people. Furthermore, guidelines are proposed to improve the design of these measures and make them more open to what people value and more sensitive to public reasoning.【17†source】.\n",
        "  **Prompt GPT**:   The main results of the text seem to focus on the challenges and limitations faced by lower-middle-income countries in conducting large-scale participatory exercises regularly. It discusses the use of qualitative research with small samples, the potential under-representation of disadvantaged voices, and the complexities of analyzing wellbeing from multiple perspectives. The text also mentions the progress made in measuring poverty in a way that better reflects what disadvantaged individuals consider a life in poverty.\n",
        "- La respuesta primera se enfoca en resaltar los avances en las medidas de pobreza y destaca que en el texto se presentan guías para mejorar el diseño de estas, mientras la segunda está más concentrada en señalar que los resultados están más enfocados en los desafíos al representar las perspectivas de individuos de bajos recursos\n",
        "\n",
        "\n",
        "3. **¿Cuáles son las diferentes formas de medir oficialmente la pobreza multidimensional en los países latinoamericanos discutidos en el texto?**\n",
        "   - Los países discutidos en el texto, Colombia, Chile, El Salvador y México, utilizan diversas estrategias y dimensiones para medir la pobreza multidimensional, incluyendo educación, salud, empleo, protección social, condiciones de vivienda y servicios básicos domésticos. Aunque cada país ha desarrollado su propio enfoque, comparten el objetivo común de incorporar dimensiones que reflejen una comprensión más amplia de la pobreza【17†source】.\n",
        "   *GPT prompt*:   The official multidimensional poverty measures in Latin American countries discussed in the text are measured using the Alkire-Foster method. This method involves selecting dimensions such as education, housing conditions, employment, health, basic services, food security, and habitat quality. These dimensions are operationalized using indicators estimated from data sources like the Living Standards Measurement Survey (LSMS). The poverty threshold is set at 1/3 of the weighted deprivation, with equal weight given to each dimension.\n",
        "- La respuesta generada por el CHAT GPT4 está más enfocadamencionar que existen diversas estrategias y objetivos que usan los países de Latinoamérica para medir la pobreza multidimensional, mientras que la generada por el prompt directamente nos indica que se usó, en estos países, el método de Alkire-Foster. Menciona la metodología para ello, mencionando los nombres de los indicadores para el logro de eso.\n",
        "\n",
        "4. **¿Cuál es la hipótesis principal del texto?**\n",
        "   - La hipótesis principal es que las medidas oficiales de pobreza multidimensional en Latinoamérica pueden reflejar mejor las prioridades de las personas en situación de pobreza si se diseñan mediante procesos que incluyan las perspectivas y valores de estas comunidades. Aunque existen limitaciones prácticas y de política, es posible avanzar hacia sistemas de medición más inclusivos y sensibles al razonamiento público【17†source\n",
        "   - **GPT prompt*:   The main hypothesis of the text seems to be that the process of designing and implementing official multidimensional national poverty measures, inspired by the Sustainable Development Goals (SDG) agenda, has been successful in partially reflecting some of the elements that disadvantaged people prioritize.\n",
        "- Si bien ambas destacan que la hipótesis principal del texto se centra en la efectividad de medidas de pobreza multidimensional utilizadas de forma oficial en América Latina para reflejar las prioridades de las personas desfavorecidas a través de procesos de diseño inclusivos, con la posibilidad de mejorar; el segundo añade que estas formas de medición existosas  son inspiradas opor los ODS\n",
        "\n",
        "\n",
        "5. **¿Cómo propone el autor que los sistemas oficiales de pobreza multidimensional puedan mejorar su apertura al público?**\n",
        "   - Los autores proponen enriquecer las fuentes de datos utilizadas para estimar la pobreza multidimensional, desarrollar medidas complementarias de pobreza multidimensional desde una perspectiva territorial y explorar sinergias con el sector privado. Estas estrategias buscan aumentar la inclusión de las perspectivas de las personas en situación de pobreza en el diseño de las medidas y hacer que el proceso de medición sea más abierto y sensible a las prioridades y valores de la población【17†source】\n",
        "   -  GPT prompt: The author suggests three areas in which official multidimensional poverty systems could enhance their openness to public reasoning. These areas include enriching the data sources used to estimate multidimensional poverty, developing complementary measures from a territorial perspective, and exploring synergies with the private sector. Additionally, the author mentions that dimensions could be chosen based on participatory deliberative processes, weights could be assigned based on how people rank these dimensions, and a poverty threshold could be set based on societal views of deprivation. However, the author also acknowledges that these approaches are not without limitations and criticisms."
      ],
      "metadata": {
        "id": "aEPcQYJwAONf"
      },
      "id": "aEPcQYJwAONf"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y9MNoogKKIQ5"
      },
      "id": "Y9MNoogKKIQ5"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}